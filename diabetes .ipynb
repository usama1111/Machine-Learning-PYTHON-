{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'Desktop\\diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Outcome\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder\n",
    "data[\"Outcome\"] = le.fit_transform(data[\"Outcome\"],data[\"Outcome\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetures_array=np.array(data.drop([\"Outcome\"],axis=1))\n",
    "labels_array=np.array(data[\"Outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fetures_array, labels_array, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Features : (576, 8)\n",
      "Train_Labels : (576,)\n",
      "Test_Features : (192, 8)\n",
      "Test_Labels : (192,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train_Features :\",X_train.shape)\n",
    "print(\"Train_Labels :\",y_train.shape)\n",
    "print(\"Test_Features :\",X_test.shape)\n",
    "print(\"Test_Labels :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy'\n",
    "              ,    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/99\n",
      "576/576 [==============================] - 0s 382us/sample - loss: 0.0957 - accuracy: 0.9688 - val_loss: 2.2804 - val_accuracy: 0.7188\n",
      "Epoch 2/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.0998 - accuracy: 0.9653 - val_loss: 2.5341 - val_accuracy: 0.7240\n",
      "Epoch 3/99\n",
      "576/576 [==============================] - 0s 353us/sample - loss: 0.1257 - accuracy: 0.9462 - val_loss: 2.1638 - val_accuracy: 0.7135\n",
      "Epoch 4/99\n",
      "576/576 [==============================] - 0s 343us/sample - loss: 0.1243 - accuracy: 0.9410 - val_loss: 2.4291 - val_accuracy: 0.6823\n",
      "Epoch 5/99\n",
      "576/576 [==============================] - 0s 348us/sample - loss: 0.1336 - accuracy: 0.9549 - val_loss: 2.2068 - val_accuracy: 0.6875\n",
      "Epoch 6/99\n",
      "576/576 [==============================] - 0s 357us/sample - loss: 0.0782 - accuracy: 0.9688 - val_loss: 2.0664 - val_accuracy: 0.6979\n",
      "Epoch 7/99\n",
      "576/576 [==============================] - 0s 345us/sample - loss: 0.1012 - accuracy: 0.9670 - val_loss: 2.2890 - val_accuracy: 0.6979\n",
      "Epoch 8/99\n",
      "576/576 [==============================] - 0s 332us/sample - loss: 0.0520 - accuracy: 0.9809 - val_loss: 2.2612 - val_accuracy: 0.7240\n",
      "Epoch 9/99\n",
      "576/576 [==============================] - 0s 376us/sample - loss: 0.0361 - accuracy: 0.9896 - val_loss: 2.4051 - val_accuracy: 0.7135\n",
      "Epoch 10/99\n",
      "576/576 [==============================] - 0s 354us/sample - loss: 0.0585 - accuracy: 0.9826 - val_loss: 2.6966 - val_accuracy: 0.6719\n",
      "Epoch 11/99\n",
      "576/576 [==============================] - 0s 354us/sample - loss: 0.1737 - accuracy: 0.9444 - val_loss: 2.4158 - val_accuracy: 0.6719\n",
      "Epoch 12/99\n",
      "576/576 [==============================] - 0s 356us/sample - loss: 0.1911 - accuracy: 0.9375 - val_loss: 1.9672 - val_accuracy: 0.6927\n",
      "Epoch 13/99\n",
      "576/576 [==============================] - 0s 343us/sample - loss: 0.1272 - accuracy: 0.9462 - val_loss: 2.0498 - val_accuracy: 0.7031\n",
      "Epoch 14/99\n",
      "576/576 [==============================] - 0s 372us/sample - loss: 0.0917 - accuracy: 0.9705 - val_loss: 2.2214 - val_accuracy: 0.6875\n",
      "Epoch 15/99\n",
      "576/576 [==============================] - 0s 361us/sample - loss: 0.0701 - accuracy: 0.9670 - val_loss: 2.3919 - val_accuracy: 0.6979\n",
      "Epoch 16/99\n",
      "576/576 [==============================] - 0s 357us/sample - loss: 0.0673 - accuracy: 0.9757 - val_loss: 2.3164 - val_accuracy: 0.7031\n",
      "Epoch 17/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.0685 - accuracy: 0.9774 - val_loss: 2.4415 - val_accuracy: 0.6927\n",
      "Epoch 18/99\n",
      "576/576 [==============================] - 0s 334us/sample - loss: 0.0497 - accuracy: 0.9861 - val_loss: 2.5192 - val_accuracy: 0.7031\n",
      "Epoch 19/99\n",
      "576/576 [==============================] - 0s 368us/sample - loss: 0.0281 - accuracy: 0.9931 - val_loss: 2.6783 - val_accuracy: 0.7240\n",
      "Epoch 20/99\n",
      "576/576 [==============================] - 0s 361us/sample - loss: 0.0151 - accuracy: 0.9983 - val_loss: 2.7371 - val_accuracy: 0.7188\n",
      "Epoch 21/99\n",
      "576/576 [==============================] - 0s 372us/sample - loss: 0.0159 - accuracy: 0.9948 - val_loss: 2.8595 - val_accuracy: 0.6979\n",
      "Epoch 22/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.0181 - accuracy: 0.9896 - val_loss: 2.9028 - val_accuracy: 0.7135\n",
      "Epoch 23/99\n",
      "576/576 [==============================] - 0s 359us/sample - loss: 0.0211 - accuracy: 0.9913 - val_loss: 2.9356 - val_accuracy: 0.7083\n",
      "Epoch 24/99\n",
      "576/576 [==============================] - 0s 354us/sample - loss: 0.0103 - accuracy: 0.9965 - val_loss: 2.9907 - val_accuracy: 0.7083\n",
      "Epoch 25/99\n",
      "576/576 [==============================] - 0s 351us/sample - loss: 0.0076 - accuracy: 0.9965 - val_loss: 3.0390 - val_accuracy: 0.6979\n",
      "Epoch 26/99\n",
      "576/576 [==============================] - 0s 369us/sample - loss: 0.0079 - accuracy: 0.9965 - val_loss: 3.0453 - val_accuracy: 0.7188\n",
      "Epoch 27/99\n",
      "576/576 [==============================] - 0s 354us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.1050 - val_accuracy: 0.6979\n",
      "Epoch 28/99\n",
      "576/576 [==============================] - 0s 354us/sample - loss: 0.0066 - accuracy: 0.9983 - val_loss: 3.1617 - val_accuracy: 0.7031\n",
      "Epoch 29/99\n",
      "576/576 [==============================] - 0s 362us/sample - loss: 0.0053 - accuracy: 0.9983 - val_loss: 3.1990 - val_accuracy: 0.6979\n",
      "Epoch 30/99\n",
      "576/576 [==============================] - 0s 368us/sample - loss: 0.0062 - accuracy: 0.9965 - val_loss: 3.2194 - val_accuracy: 0.7083\n",
      "Epoch 31/99\n",
      "576/576 [==============================] - 0s 354us/sample - loss: 0.0058 - accuracy: 0.9983 - val_loss: 3.2491 - val_accuracy: 0.6979\n",
      "Epoch 32/99\n",
      "576/576 [==============================] - 0s 361us/sample - loss: 0.0090 - accuracy: 0.9965 - val_loss: 3.2423 - val_accuracy: 0.6823\n",
      "Epoch 33/99\n",
      "576/576 [==============================] - 0s 361us/sample - loss: 0.0075 - accuracy: 0.9965 - val_loss: 3.2755 - val_accuracy: 0.6979\n",
      "Epoch 34/99\n",
      "576/576 [==============================] - 0s 361us/sample - loss: 0.0070 - accuracy: 0.9965 - val_loss: 3.3501 - val_accuracy: 0.6823\n",
      "Epoch 35/99\n",
      "576/576 [==============================] - 0s 368us/sample - loss: 0.0074 - accuracy: 0.9965 - val_loss: 3.3416 - val_accuracy: 0.7031\n",
      "Epoch 36/99\n",
      "576/576 [==============================] - 0s 355us/sample - loss: 0.0066 - accuracy: 0.9948 - val_loss: 3.3581 - val_accuracy: 0.7031\n",
      "Epoch 37/99\n",
      "576/576 [==============================] - 0s 367us/sample - loss: 0.0063 - accuracy: 0.9948 - val_loss: 3.4010 - val_accuracy: 0.6979\n",
      "Epoch 38/99\n",
      "576/576 [==============================] - 0s 354us/sample - loss: 0.0063 - accuracy: 0.9965 - val_loss: 3.4607 - val_accuracy: 0.6875\n",
      "Epoch 39/99\n",
      "576/576 [==============================] - 0s 364us/sample - loss: 0.0057 - accuracy: 0.9948 - val_loss: 3.4431 - val_accuracy: 0.6979\n",
      "Epoch 40/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.0052 - accuracy: 0.9965 - val_loss: 3.4727 - val_accuracy: 0.7031\n",
      "Epoch 41/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.0053 - accuracy: 0.9948 - val_loss: 3.4829 - val_accuracy: 0.7031\n",
      "Epoch 42/99\n",
      "576/576 [==============================] - 0s 348us/sample - loss: 0.0067 - accuracy: 0.9965 - val_loss: 3.5216 - val_accuracy: 0.6927\n",
      "Epoch 43/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.0074 - accuracy: 0.9965 - val_loss: 3.4816 - val_accuracy: 0.6979\n",
      "Epoch 44/99\n",
      "576/576 [==============================] - 0s 361us/sample - loss: 0.0073 - accuracy: 0.9965 - val_loss: 3.5705 - val_accuracy: 0.6979\n",
      "Epoch 45/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.0063 - accuracy: 0.9965 - val_loss: 3.5667 - val_accuracy: 0.7031\n",
      "Epoch 46/99\n",
      "576/576 [==============================] - 0s 351us/sample - loss: 0.0060 - accuracy: 0.9948 - val_loss: 3.6032 - val_accuracy: 0.7031\n",
      "Epoch 47/99\n",
      "576/576 [==============================] - 0s 371us/sample - loss: 0.0142 - accuracy: 0.9931 - val_loss: 3.6440 - val_accuracy: 0.6875\n",
      "Epoch 48/99\n",
      "576/576 [==============================] - 0s 362us/sample - loss: 0.0397 - accuracy: 0.9913 - val_loss: 3.5956 - val_accuracy: 0.7083\n",
      "Epoch 49/99\n",
      "576/576 [==============================] - 0s 353us/sample - loss: 0.0684 - accuracy: 0.9688 - val_loss: 3.2839 - val_accuracy: 0.7240\n",
      "Epoch 50/99\n",
      "576/576 [==============================] - 0s 354us/sample - loss: 0.2005 - accuracy: 0.9323 - val_loss: 3.4821 - val_accuracy: 0.6927\n",
      "Epoch 51/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.4548 - accuracy: 0.8559 - val_loss: 2.0589 - val_accuracy: 0.7083\n",
      "Epoch 52/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.3640 - accuracy: 0.8090 - val_loss: 1.3426 - val_accuracy: 0.6719\n",
      "Epoch 53/99\n",
      "576/576 [==============================] - 0s 361us/sample - loss: 0.3241 - accuracy: 0.8368 - val_loss: 1.4218 - val_accuracy: 0.6719\n",
      "Epoch 54/99\n",
      "576/576 [==============================] - 0s 403us/sample - loss: 0.2208 - accuracy: 0.9097 - val_loss: 1.8165 - val_accuracy: 0.7135\n",
      "Epoch 55/99\n",
      "576/576 [==============================] - 0s 390us/sample - loss: 0.1552 - accuracy: 0.9410 - val_loss: 1.9785 - val_accuracy: 0.7135\n",
      "Epoch 56/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 340us/sample - loss: 0.1175 - accuracy: 0.9601 - val_loss: 2.2237 - val_accuracy: 0.7344\n",
      "Epoch 57/99\n",
      "576/576 [==============================] - 0s 344us/sample - loss: 0.1427 - accuracy: 0.9479 - val_loss: 2.2295 - val_accuracy: 0.7031\n",
      "Epoch 58/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.1005 - accuracy: 0.9583 - val_loss: 2.5167 - val_accuracy: 0.7031\n",
      "Epoch 59/99\n",
      "576/576 [==============================] - 0s 341us/sample - loss: 0.0834 - accuracy: 0.9740 - val_loss: 2.6061 - val_accuracy: 0.7188\n",
      "Epoch 60/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.1575 - accuracy: 0.9514 - val_loss: 2.2123 - val_accuracy: 0.6979\n",
      "Epoch 61/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.2015 - accuracy: 0.9253 - val_loss: 1.4913 - val_accuracy: 0.6771\n",
      "Epoch 62/99\n",
      "576/576 [==============================] - 0s 326us/sample - loss: 0.1552 - accuracy: 0.9410 - val_loss: 1.7623 - val_accuracy: 0.7135\n",
      "Epoch 63/99\n",
      "576/576 [==============================] - 0s 362us/sample - loss: 0.0870 - accuracy: 0.9653 - val_loss: 2.1165 - val_accuracy: 0.6875\n",
      "Epoch 64/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.0821 - accuracy: 0.9757 - val_loss: 2.4506 - val_accuracy: 0.6927\n",
      "Epoch 65/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.0526 - accuracy: 0.9878 - val_loss: 2.5817 - val_accuracy: 0.7083\n",
      "Epoch 66/99\n",
      "576/576 [==============================] - 0s 333us/sample - loss: 0.0786 - accuracy: 0.9670 - val_loss: 2.4526 - val_accuracy: 0.6719\n",
      "Epoch 67/99\n",
      "576/576 [==============================] - 0s 346us/sample - loss: 0.1381 - accuracy: 0.9601 - val_loss: 2.6521 - val_accuracy: 0.6250\n",
      "Epoch 68/99\n",
      "576/576 [==============================] - 0s 349us/sample - loss: 0.2217 - accuracy: 0.9149 - val_loss: 2.2377 - val_accuracy: 0.6771\n",
      "Epoch 69/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.1335 - accuracy: 0.9462 - val_loss: 2.2835 - val_accuracy: 0.6927\n",
      "Epoch 70/99\n",
      "576/576 [==============================] - 0s 348us/sample - loss: 0.0726 - accuracy: 0.9757 - val_loss: 2.3217 - val_accuracy: 0.6979\n",
      "Epoch 71/99\n",
      "576/576 [==============================] - 0s 375us/sample - loss: 0.0376 - accuracy: 0.9931 - val_loss: 2.5861 - val_accuracy: 0.6979\n",
      "Epoch 72/99\n",
      "576/576 [==============================] - 0s 391us/sample - loss: 0.0321 - accuracy: 0.9931 - val_loss: 2.9025 - val_accuracy: 0.7083\n",
      "Epoch 73/99\n",
      "576/576 [==============================] - 0s 372us/sample - loss: 0.0200 - accuracy: 0.9913 - val_loss: 3.1083 - val_accuracy: 0.7240\n",
      "Epoch 74/99\n",
      "576/576 [==============================] - 0s 375us/sample - loss: 0.0187 - accuracy: 0.9931 - val_loss: 3.2310 - val_accuracy: 0.7240\n",
      "Epoch 75/99\n",
      "576/576 [==============================] - 0s 368us/sample - loss: 0.0111 - accuracy: 0.9965 - val_loss: 3.4349 - val_accuracy: 0.6927\n",
      "Epoch 76/99\n",
      "576/576 [==============================] - 0s 375us/sample - loss: 0.0093 - accuracy: 0.9965 - val_loss: 3.5472 - val_accuracy: 0.7083\n",
      "Epoch 77/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.0067 - accuracy: 0.9983 - val_loss: 3.5962 - val_accuracy: 0.7031\n",
      "Epoch 78/99\n",
      "576/576 [==============================] - 0s 389us/sample - loss: 0.0075 - accuracy: 0.9965 - val_loss: 3.7051 - val_accuracy: 0.7083\n",
      "Epoch 79/99\n",
      "576/576 [==============================] - 0s 361us/sample - loss: 0.0079 - accuracy: 0.9965 - val_loss: 3.7680 - val_accuracy: 0.7083\n",
      "Epoch 80/99\n",
      "576/576 [==============================] - 0s 389us/sample - loss: 0.0088 - accuracy: 0.9965 - val_loss: 3.8951 - val_accuracy: 0.7031\n",
      "Epoch 81/99\n",
      "576/576 [==============================] - 0s 406us/sample - loss: 0.0086 - accuracy: 0.9965 - val_loss: 3.8499 - val_accuracy: 0.6979\n",
      "Epoch 82/99\n",
      "576/576 [==============================] - 0s 368us/sample - loss: 0.0254 - accuracy: 0.9948 - val_loss: 3.7649 - val_accuracy: 0.7135\n",
      "Epoch 83/99\n",
      "576/576 [==============================] - 0s 352us/sample - loss: 0.0483 - accuracy: 0.9809 - val_loss: 3.8432 - val_accuracy: 0.6875\n",
      "Epoch 84/99\n",
      "576/576 [==============================] - 0s 382us/sample - loss: 0.0411 - accuracy: 0.9826 - val_loss: 3.6328 - val_accuracy: 0.6979\n",
      "Epoch 85/99\n",
      "576/576 [==============================] - 0s 381us/sample - loss: 0.0339 - accuracy: 0.9826 - val_loss: 3.6786 - val_accuracy: 0.6979\n",
      "Epoch 86/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.1190 - accuracy: 0.9549 - val_loss: 3.7665 - val_accuracy: 0.6615\n",
      "Epoch 87/99\n",
      "576/576 [==============================] - 0s 374us/sample - loss: 0.1471 - accuracy: 0.9497 - val_loss: 3.1898 - val_accuracy: 0.7083\n",
      "Epoch 88/99\n",
      "576/576 [==============================] - 0s 372us/sample - loss: 0.1104 - accuracy: 0.9635 - val_loss: 2.9362 - val_accuracy: 0.7031\n",
      "Epoch 89/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.0494 - accuracy: 0.9826 - val_loss: 2.9831 - val_accuracy: 0.7031\n",
      "Epoch 90/99\n",
      "576/576 [==============================] - 0s 326us/sample - loss: 0.0435 - accuracy: 0.9878 - val_loss: 3.1738 - val_accuracy: 0.7188\n",
      "Epoch 91/99\n",
      "576/576 [==============================] - 0s 388us/sample - loss: 0.0398 - accuracy: 0.9878 - val_loss: 3.2928 - val_accuracy: 0.7083\n",
      "Epoch 92/99\n",
      "576/576 [==============================] - 0s 366us/sample - loss: 0.0457 - accuracy: 0.9844 - val_loss: 3.2040 - val_accuracy: 0.7031\n",
      "Epoch 93/99\n",
      "576/576 [==============================] - 0s 389us/sample - loss: 0.0385 - accuracy: 0.9844 - val_loss: 3.5361 - val_accuracy: 0.7031\n",
      "Epoch 94/99\n",
      "576/576 [==============================] - 0s 340us/sample - loss: 0.0224 - accuracy: 0.9913 - val_loss: 3.5396 - val_accuracy: 0.7031\n",
      "Epoch 95/99\n",
      "576/576 [==============================] - 0s 365us/sample - loss: 0.0135 - accuracy: 0.9948 - val_loss: 3.5701 - val_accuracy: 0.7031\n",
      "Epoch 96/99\n",
      "576/576 [==============================] - 0s 347us/sample - loss: 0.0157 - accuracy: 0.9931 - val_loss: 3.6633 - val_accuracy: 0.7188\n",
      "Epoch 97/99\n",
      "576/576 [==============================] - 0s 368us/sample - loss: 0.0315 - accuracy: 0.9896 - val_loss: 3.6046 - val_accuracy: 0.7135\n",
      "Epoch 98/99\n",
      "576/576 [==============================] - 0s 375us/sample - loss: 0.0650 - accuracy: 0.9722 - val_loss: 3.5649 - val_accuracy: 0.6927\n",
      "Epoch 99/99\n",
      "576/576 [==============================] - 0s 343us/sample - loss: 0.1310 - accuracy: 0.9514 - val_loss: 3.2558 - val_accuracy: 0.7031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7700aca448>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=99 ,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "192/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 105us/sample - loss: 2.4464 - accuracy: 0.7031\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test,  y_test, verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value : [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted value :\",model.predict_classes(X_train[[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   180.    78.    63.    14.    59.4    2.42  25.  ]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
